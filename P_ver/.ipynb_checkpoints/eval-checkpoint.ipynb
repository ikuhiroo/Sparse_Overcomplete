{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 定性評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -----------初期設定-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# python3\n",
    "#\n",
    "import argparse\n",
    "import gzip\n",
    "import math\n",
    "import numpy\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import codecs\n",
    "from statistics import mean, median,variance,stdev\n",
    "import pandas as pd\n",
    "import pandas_profiling as pdp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "newvec = joblib.load(\"./model/factor10_iter42/newvec_42.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# def similarity(v1, v2):\n",
    "#     n1 = np.linalg.norm(v1) # v1のノルム\n",
    "#     n2 = np.linalg.norm(v2) # v2のノルム\n",
    "#     return np.dot(v1, v2) / (n1*n2) # 内積 / "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Qualitative_Evaluation（各次元の外れ値（ =分散が大きい）の単語Top5）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 単語ベクトル\n",
    "newvec_word = list(newvec.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# wordをidで対応づけるためのdataframe\n",
    "f_word = pd.DataFrame(newvec_word, columns=['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 分散ベクトル\n",
    "newvec_dimention = list(newvec.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# limitまでの次元まで (全単語の100次元までを集計)\n",
    "# valueを保存する\n",
    "var_per_dimention = {}\n",
    "limit_num = 100\n",
    "for v in range(len(newvec_dimention)):\n",
    "    for j in range(len(newvec_dimention[v][0])):\n",
    "        if j < limit_num:\n",
    "            try:\n",
    "                var_per_dimention[j].append(newvec_dimention[v][0][j])\n",
    "            except:\n",
    "                var_per_dimention[j] = [newvec_dimention[v][0][j]]\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 単語操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 次元ごとに0占有率に関するリストを作成する\n",
    "memo_80 = []\n",
    "memo_80_85 = []\n",
    "memo_85_90 = []\n",
    "memo_90_95 = []\n",
    "memo_95 = []\n",
    "memo_96 = []\n",
    "memo_97 = []\n",
    "memo_98 = []\n",
    "memo_99 = []\n",
    "memo_other = []\n",
    "for i in range(len(list(var_per_dimention.values()))):\n",
    "    x = list(var_per_dimention.values())[i]\n",
    "    if (x.count(0) / len(x)) * 100 < 80:\n",
    "        memo_80.append(i)\n",
    "    elif (x.count(0) / len(x)) * 100 >= 80 and (x.count(0) / len(x)) * 100 < 85:\n",
    "        memo_80_85.append(i)\n",
    "    elif (x.count(0) / len(x)) * 100 >= 85 and (x.count(0) / len(x)) * 100 < 90:\n",
    "        memo_85_90.append(i)\n",
    "    elif (x.count(0) / len(x)) * 100 <= 90 and (x.count(0) / len(x)) * 100 < 95:\n",
    "        memo_90_95.append(i)\n",
    "    elif (x.count(0) / len(x)) * 100 == 95:\n",
    "        memo_95.append(i)\n",
    "    elif (x.count(0) / len(x)) * 100 == 96:\n",
    "        memo_96.append(i)\n",
    "    elif (x.count(0) / len(x)) * 100 == 97:\n",
    "        memo_97.append(i)\n",
    "    elif (x.count(0) / len(x)) * 100 == 98:\n",
    "        memo_98.append(i)\n",
    "    elif (x.count(0) / len(x)) * 100 == 99:\n",
    "        memo_99.append(i)\n",
    "    else:\n",
    "        memo_other.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# cntを算出する\n",
    "cnt_result = []\n",
    "cnt_result.append(len(memo_80))\n",
    "cnt_result.append(len(memo_80_85))\n",
    "cnt_result.append(len(memo_85_90))\n",
    "cnt_result.append(len(memo_90_95))\n",
    "cnt_result.append(len(memo_95))\n",
    "cnt_result.append(len(memo_96))\n",
    "cnt_result.append(len(memo_97))\n",
    "cnt_result.append(len(memo_98))\n",
    "cnt_result.append(len(memo_99))\n",
    "cnt_result.append(len(memo_other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 特定の次元の平均を求める\n",
    "for d in memo_99:\n",
    "    # i番目の次元のベクトルに注目\n",
    "    x = list(var_per_dimention.values())[d]\n",
    "    # 平均を求める\n",
    "    mean_x = np.average(x)\n",
    "    logger.info(\"d: {}, mean: {}\\n\".format(d, mean_x))\n",
    "\n",
    "    # 求めた平均から各単語の分散を求める\n",
    "    var_x = [math.sqrt((mean_x - x[i]) ** 2) for i in range(len(x))]\n",
    "\n",
    "    # 分散の大きさ順にソートし，indexを返す\n",
    "    index_x_sorted = sorted(\n",
    "        range(len(var_x)), key=lambda k: var_x[k], reverse=True\n",
    "    )\n",
    "\n",
    "    # indexの上位5個\n",
    "    target = index_x_sorted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# f_dimention = pd.DataFrame(list(var_per_dimention.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pdp.ProfileReport(f_dimention.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -----------ある単語の類似する単語を挙げる-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def checkSim_by_word(vecs, word):\n",
    "    # 閾値の設定\n",
    "    negative = False # Falseなら似た単語を候補で上げる\n",
    "    threshold = 0.5 # -1なら閾値固定\n",
    "    border_positive = threshold if threshold > 0 else 0.8\n",
    "    border_negative = threshold if threshold > 0 else 0.3\n",
    "\n",
    "    # 候補数の設定\n",
    "    max_candidates = 20\n",
    "    candidates = {}\n",
    "    \n",
    "    # wordの設定確認\n",
    "    if not word:\n",
    "        raise Exception(\"word is missing\")\n",
    "\n",
    "    # wordがモデルにない場合，\n",
    "    if word not in vecs:\n",
    "        raise Exception(\"Sorry, this word is not registered in model.\")\n",
    "\n",
    "    # ベクトルの設定\n",
    "    w_vec = vecs[word]\n",
    "    for w in vecs:\n",
    "        try:\n",
    "            if w_vec.shape != vecs[w].shape:\n",
    "                raise Exception(\"size not match\")\n",
    "            s = similarity(w_vec, vecs[w])\n",
    "        except Exception as ex:\n",
    "            print(w + \" is not valid word.\")\n",
    "            continue\n",
    "\n",
    "        if negative and s <= border_negative:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_negative -= 0.05\n",
    "        elif not negative and s >= border_positive:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_positive += 0.05\n",
    "\n",
    "        if len(candidates) > max_candidates:\n",
    "            break\n",
    "    \n",
    "    # 類義語算出\n",
    "    sorted_candidates = sorted(candidates, key=candidates.get, reverse=not negative)\n",
    "    for c in sorted_candidates:\n",
    "        print(\"{0}, {1}\".format(c, candidates[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word = 'on'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 初期vecの場合，\n",
    "checkSim_by_word(vecs_wordVecs, word)\n",
    "print(' ')\n",
    "# newvecの場合，\n",
    "checkSim_by_word(vecs_new_vec, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -----------WordSim評価-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# word2vec\n",
    "vecs_wordVecs = wordVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# newvec\n",
    "vecs_new_vec = new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def checkSim(v1, v2):\n",
    "    if v1 not in lexicon: # 注目単語がwordnetに含まれない場合，\n",
    "        print(\"v1(={})はwordnetのkeyに存在しません\".format(v1))\n",
    "        wordNeighbours_1 = set()\n",
    "    else:\n",
    "        # 注目単語の同義語リストとword2vecのkeyリストと重複する単語リスト（更新対象か？）\n",
    "        wordNeighbours_1 = set(lexicon[v1]).intersection(set(wordVecs.keys()))\n",
    "        print('v1(={})における更新対象のneighbour数 : {}'.format(v1, len(wordNeighbours_1)))\n",
    "        \n",
    "    # neighboursの中で注目単語と類似度が低いもの\n",
    "    ave_1_word2vec = np.zeros_like(wordVecs[v1])  #neighboursの平均ベクトル\n",
    "    ave_1_retrofit = np.zeros_like(wordVecs[v1])\n",
    "    for neighbour in wordNeighbours_1:\n",
    "        print('v1とneighbour(={}) : {} -> {}'.format(neighbour, \n",
    "                                                                   similarity(wordVecs[neighbour], wordVecs[v1]), \n",
    "                                                                   similarity(vecs_new_vec[neighbour], vecs_new_vec[v1])))\n",
    "        ave_1_word2vec += wordVecs[neighbour]\n",
    "        ave_1_retrofit += vecs_new_vec[neighbour]\n",
    "    print('v1とneighboursの平均ベクトル : {} -> {}'.format(similarity(ave_1_word2vec/len(wordNeighbours_1), wordVecs[v1]), \n",
    "                                                              similarity(ave_1_retrofit/len(wordNeighbours_1), vecs_new_vec[v1])))\n",
    "    print(\" \")\n",
    "    \n",
    "    if v2 not in lexicon:\n",
    "        print(\"v2(={})はwordnetのkeyに存在しません\".format(v2))\n",
    "        wordNeighbours_2 = set()\n",
    "    else:\n",
    "        wordNeighbours_2 = set(lexicon[v2]).intersection(set(wordVecs.keys()))\n",
    "        print('v2(={})における更新対象のneighbour数 : {}'.format(v2, len(wordNeighbours_2))) # 更新対象数\n",
    "    \n",
    "    # neighboursの中で注目単語と類似度が低いもの\n",
    "    ave_2_word2vec = np.zeros_like(wordVecs[v2])  #neighboursの平均ベクトル\n",
    "    ave_2_retrofit = np.zeros_like(wordVecs[v2])\n",
    "    for neighbour in wordNeighbours_2:\n",
    "        print('v2とneighbour(={}) : {} -> {}'.format(neighbour, \n",
    "                                                                   similarity(wordVecs[neighbour], wordVecs[v2]), \n",
    "                                                                   similarity(vecs_new_vec[neighbour], vecs_new_vec[v2])))\n",
    "        ave_2_word2vec += wordVecs[neighbour]\n",
    "        ave_2_retrofit += vecs_new_vec[neighbour]\n",
    "    print('v2とneighboursの平均ベクトル : {} -> {}'.format(similarity(ave_2_word2vec/len(wordNeighbours_2), wordVecs[v2]), \n",
    "                                                              similarity(ave_2_retrofit/len(wordNeighbours_2), vecs_new_vec[v2])))\n",
    "    print(\" \")\n",
    "    \n",
    "    # v1とv2における更新対象のneighbourに重複があるか\n",
    "    print('更新対象における重複 : {}'.format(set(wordNeighbours_1).intersection(set(wordNeighbours_2))))\n",
    "    print('更新対象における重複数 : {}'.format(len(set(wordNeighbours_1).intersection(set(wordNeighbours_2)))))\n",
    "    print(\" \")\n",
    "\n",
    "    \"\"\"v1とv2のword2vecとretrofittingにおける類似度\"\"\"\n",
    "    try:\n",
    "        print(\"word2vec : {}\".format(similarity(vecs_wordVecs[v1], vecs_wordVecs[v2])))\n",
    "    except:\n",
    "        print('error')\n",
    "\n",
    "    try:\n",
    "        print(\"retrofitting : {}\".format(similarity(vecs_new_vec[v1], vecs_new_vec[v2])))\n",
    "    except:\n",
    "        print('error')\n",
    "\n",
    "    print(\" \")\n",
    "    \"\"\"同一単語におけるword2vecとretrofittingの類似度\"\"\"\n",
    "    try:\n",
    "        print(\"v1 : {}\".format(similarity(vecs_wordVecs[v1], vecs_new_vec[v1])))\n",
    "    except:\n",
    "        print('error')\n",
    "\n",
    "    try:\n",
    "        print(\"v2 : {}\".format(similarity(vecs_wordVecs[v2], vecs_new_vec[v2])))\n",
    "    except:\n",
    "        print('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ・WordSimのテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v1 = 'フットボール'\n",
    "v2 = 'サッカー'\n",
    "# checkSim(v1, v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -----------wordAnalogy評価-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def checkAnalogy(vecs, w_vec):  \n",
    "    negative = False # Falseなら似た単語を候補で上げる\n",
    "    threshold = 0.3 # -1なら閾値固定\n",
    "\n",
    "    # 閾値の設定\n",
    "    border_positive = threshold if threshold > 0 else 0.9\n",
    "    border_negative = threshold if threshold > 0 else 0.2\n",
    "    print('{} < thd < {}'.format(border_negative, border_positive))\n",
    "\n",
    "    # 候補数の設定\n",
    "    max_candidates = 20\n",
    "    candidates = {}\n",
    "\n",
    "    for w in vecs:\n",
    "        try:\n",
    "            if w_vec.shape != vecs[w].shape:\n",
    "                raise Exception(\"size not match\")\n",
    "            s = similarity(w_vec, vecs[w])\n",
    "        except Exception as ex:\n",
    "            print(w + \" is not valid word.\")\n",
    "            continue\n",
    "\n",
    "        if negative and s <= border_negative:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_negative -= 0.05\n",
    "        elif not negative and s >= border_positive:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_positive += 0.05\n",
    "\n",
    "        if len(candidates) > max_candidates:\n",
    "            break\n",
    "\n",
    "    # 類義語算出\n",
    "    sorted_candidates = sorted(candidates, key=candidates.get, reverse=not negative)\n",
    "    for c in sorted_candidates:\n",
    "        print(\"{0}, {1}\".format(c, candidates[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ・「v1 + v2 - v3」と「v4」の類似度算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "v1 = '兄'\n",
    "v2 = '姉'\n",
    "v3 = '祖父'\n",
    "v4 = '祖母'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if v1 not in lexicon:\n",
    "    print(\"v1 not found error in dict\")\n",
    "if v2 not in lexicon:\n",
    "    print(\"v2 not found error in dict\")\n",
    "if v3 not in lexicon:\n",
    "    print(\"v3 not found error in dict\")\n",
    "if v4 not in lexicon:\n",
    "    print(\"v4 not found error in dict\")\n",
    "\n",
    "try:\n",
    "    print('word2vec : {}'.format(similarity(vecs_wordVecs[v1] + vecs_wordVecs[v2] - vecs_wordVecs[v3], vecs_wordVecs[v4])))\n",
    "except:\n",
    "    print('error')\n",
    "\n",
    "try:\n",
    "    print('retrofitting : {}'.format(similarity(vecs_new_vec[v1] + vecs_new_vec[v2] - vecs_new_vec[v3], vecs_new_vec[v4])))\n",
    "except:\n",
    "    print('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ・「v1 + v2 - v3」と近い単語を挙げる→「v4」が結果に出るか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 初期vecの場合，\n",
    "checkAnalogy(vecs_wordVecs, vecs_wordVecs[v1] + vecs_wordVecs[v2] - vecs_wordVecs[v3])\n",
    "print(' ')\n",
    "# newvecの場合，\n",
    "checkAnalogy(vecs_new_vec, vecs_new_vec[v1] + vecs_new_vec[v2] - vecs_new_vec[v3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
