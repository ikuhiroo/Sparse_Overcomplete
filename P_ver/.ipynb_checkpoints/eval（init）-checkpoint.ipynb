{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 定性評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -----------初期設定-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# python3\n",
    "#\n",
    "import argparse\n",
    "import gzip\n",
    "import math\n",
    "import numpy\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import codecs\n",
    "from statistics import mean, median,variance,stdev\n",
    "import pandas as pd\n",
    "import pandas_profiling as pdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "newvec = joblib.load(\"./trained_model/numIter = 6_l1_reg = 0.5_l2_reg = 1e-5_factor = 3_rate = 0.05_learning rate/newvec_5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# isNumber = re.compile(r'\\d+.*')\n",
    "# def norm_word(word):\n",
    "#     if isNumber.search(word.lower()):\n",
    "#         return '---num---'\n",
    "#     elif re.sub(r'\\W+', '', word) == '':\n",
    "#         return '---punc---'\n",
    "#     else:\n",
    "#         return word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"vectorsのread + normalize\"\"\"\n",
    "# def ReadVecsFromFile(filename):\n",
    "#     wordVectors = {}\n",
    "#     # ファイル読み込み\n",
    "#     if filename.endswith('.gz'):\n",
    "#         fileObject = gzip.open(filename, 'r')\n",
    "#     else:\n",
    "#         fileObject = codecs.open(filename, \"r\", \"utf-8\", 'ignore')\n",
    "\n",
    "#     for line in fileObject:\n",
    "#         # line = line.strip().lower()\n",
    "#         line = line.strip()\n",
    "#         word = line.split()[0]\n",
    "#         wordVectors[word] = np.zeros(len(line.split())-1, dtype=float)  # (L,)\n",
    "#         for index, vecVal in enumerate(line.split()[1:]):\n",
    "#             wordVectors[word][index] = float(vecVal)\n",
    "#         \"\"\"normalize weight vector\"\"\"\n",
    "#         wordVectors[word] /= [math.sqrt((wordVectors[word]**2).sum() + 1e-6)]\n",
    "#         wordVectors[word] = np.array([wordVectors[word]]) # (1, L)\n",
    "\n",
    "#     sys.stderr.write(\"Vectors read from: \"+filename+\" \\n\")\n",
    "#     return wordVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"vectorsのread + normalize\"\"\"\n",
    "# def ReadVecsFromFile_non(filename):\n",
    "#     wordVectors = {}\n",
    "#     # ファイル読み込み\n",
    "#     if filename.endswith('.gz'):\n",
    "#         fileObject = gzip.open(filename, 'r')\n",
    "#     else:\n",
    "#         fileObject = codecs.open(filename, \"r\", \"utf-8\", 'ignore')\n",
    "\n",
    "#     for line in fileObject:\n",
    "#         # line = line.strip().lower()\n",
    "#         line = line.strip()\n",
    "#         word = line.split()[0]\n",
    "#         wordVectors[word] = np.zeros(len(line.split())-1, dtype=float)  # (L,)\n",
    "#         for index, vecVal in enumerate(line.split()[1:]):\n",
    "#             wordVectors[word][index] = float(vecVal)\n",
    "# #         \"\"\"normalize weight vector\"\"\"\n",
    "# #         wordVectors[word] /= [math.sqrt((wordVectors[word]**2).sum() + 1e-6)]\n",
    "# #         wordVectors[word] = np.array([wordVectors[word]]) # (1, L)\n",
    "\n",
    "#     sys.stderr.write(\"Vectors read from: \"+filename+\" \\n\")\n",
    "#     return wordVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"vector A の書き込み\"\"\"\n",
    "# def WriteVectorsToFile(newvec, outFileName):\n",
    "#     \"\"\"Write word vectors to file\"\"\"\n",
    "#     sys.stderr.write('\\nWriting down the vectors in '+outFileName+'\\n')\n",
    "#     outFile = open(outFileName, 'w')\n",
    "#     for word in newvec.keys():\n",
    "#         outFile.write(word+' ')\n",
    "#         for val in newvec[word][0]:\n",
    "#             outFile.write('%.4f' % (val)+' ')\n",
    "#         outFile.write('\\n')\n",
    "#     outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# def similarity(v1, v2):\n",
    "#     n1 = np.linalg.norm(v1) # v1のノルム\n",
    "#     n2 = np.linalg.norm(v2) # v2のノルム\n",
    "#     return np.dot(v1, v2) / (n1*n2) # 内積 / "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Qualitative_Evaluation（各次元の外れ値（ =分散が大きい）の単語Top5）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "newvec_word = list(newvec.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f_word = pd.DataFrame(newvec_word, columns=['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>の</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>、</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>に</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>は</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>する</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>を</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>た</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>が</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>て</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>と</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>で</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>だ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>れる</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ある</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>いる</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>も</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>・</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>から</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>なる</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>こと</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ない</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>として</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>や</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>『</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>など</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>』</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>この</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>られる</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ため</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754039</th>\n",
       "      <td>塚本幼稚園</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754040</th>\n",
       "      <td>トィホメリ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754041</th>\n",
       "      <td>兼多</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754042</th>\n",
       "      <td>大和田廣樹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754043</th>\n",
       "      <td>蓼丸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754044</th>\n",
       "      <td>IDOLNEWSING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754045</th>\n",
       "      <td>能計以土介</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754046</th>\n",
       "      <td>Tirigan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754047</th>\n",
       "      <td>グリューネ・プンクト</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754048</th>\n",
       "      <td>PROEUROPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754049</th>\n",
       "      <td>デヴィッド・ラザルス</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754050</th>\n",
       "      <td>ニャンデバ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754051</th>\n",
       "      <td>齋藤道三</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754052</th>\n",
       "      <td>萩嶺</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754053</th>\n",
       "      <td>グレーヴェンヴィースバッハ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754054</th>\n",
       "      <td>SevenChurches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754055</th>\n",
       "      <td>Reifert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754056</th>\n",
       "      <td>Unionist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754057</th>\n",
       "      <td>トゥルイ・ウルス</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754058</th>\n",
       "      <td>グライエフ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754059</th>\n",
       "      <td>拉珈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754060</th>\n",
       "      <td>知波夜比古神社</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754061</th>\n",
       "      <td>LindafHageby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754062</th>\n",
       "      <td>Schartau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754063</th>\n",
       "      <td>ムンティギ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754064</th>\n",
       "      <td>袪</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754065</th>\n",
       "      <td>andNobukazuNAKAGOSHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754066</th>\n",
       "      <td>宇水</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754067</th>\n",
       "      <td>遥佳</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754068</th>\n",
       "      <td>マンガル・ショブハジャトラ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>754069 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        word\n",
       "0                       </s>\n",
       "1                          の\n",
       "2                          、\n",
       "3                          に\n",
       "4                          は\n",
       "5                         する\n",
       "6                          を\n",
       "7                          た\n",
       "8                          が\n",
       "9                          て\n",
       "10                         と\n",
       "11                         で\n",
       "12                         だ\n",
       "13                        れる\n",
       "14                        ある\n",
       "15                        いる\n",
       "16                         も\n",
       "17                         ・\n",
       "18                        から\n",
       "19                        なる\n",
       "20                        こと\n",
       "21                        ない\n",
       "22                       として\n",
       "23                         や\n",
       "24                         『\n",
       "25                        など\n",
       "26                         』\n",
       "27                        この\n",
       "28                       られる\n",
       "29                        ため\n",
       "...                      ...\n",
       "754039                 塚本幼稚園\n",
       "754040                 トィホメリ\n",
       "754041                    兼多\n",
       "754042                 大和田廣樹\n",
       "754043                    蓼丸\n",
       "754044           IDOLNEWSING\n",
       "754045                 能計以土介\n",
       "754046               Tirigan\n",
       "754047            グリューネ・プンクト\n",
       "754048             PROEUROPE\n",
       "754049            デヴィッド・ラザルス\n",
       "754050                 ニャンデバ\n",
       "754051                  齋藤道三\n",
       "754052                    萩嶺\n",
       "754053         グレーヴェンヴィースバッハ\n",
       "754054         SevenChurches\n",
       "754055               Reifert\n",
       "754056              Unionist\n",
       "754057              トゥルイ・ウルス\n",
       "754058                 グライエフ\n",
       "754059                    拉珈\n",
       "754060               知波夜比古神社\n",
       "754061          LindafHageby\n",
       "754062              Schartau\n",
       "754063                 ムンティギ\n",
       "754064                     袪\n",
       "754065  andNobukazuNAKAGOSHI\n",
       "754066                    宇水\n",
       "754067                    遥佳\n",
       "754068         マンガル・ショブハジャトラ\n",
       "\n",
       "[754069 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "newvec_dimention = list(newvec.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# limitまでの次元まで (全単語の100次元までを集計)\n",
    "var_per_dimention = {}\n",
    "limit_num = 100\n",
    "for v in range(len(newvec_dimention)):\n",
    "    for j in range(len(newvec_dimention[v][0])):\n",
    "        if j < limit_num:\n",
    "            try:\n",
    "                var_per_dimention[j].append(newvec_dimention[v][0][j])\n",
    "            except:\n",
    "                var_per_dimention[j] = [newvec_dimention[v][0][j]]\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単語操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 特定の次元の平均を求める\n",
    "x = list(var_per_dimention.values())[30]\n",
    "mean_x = np.average(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 求めた平均から各単語の分散を求める\n",
    "var_x = [math.sqrt((mean_x - x[i])**2) for i in range(len(x))]\n",
    "\n",
    "# 分散の大きさ順にソートし，indexを返す\n",
    "index_x_sorted = sorted(range(len(var_x)), key=lambda k: var_x[k], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114101</th>\n",
       "      <td>もう半分</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94739</th>\n",
       "      <td>マタタビ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33536</th>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75829</th>\n",
       "      <td>キルギス共和国</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92307</th>\n",
       "      <td>上葉</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word\n",
       "114101     もう半分\n",
       "94739      マタタビ\n",
       "33536       227\n",
       "75829   キルギス共和国\n",
       "92307        上葉"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexの上位5個\n",
    "target = index_x_sorted[:5]\n",
    "# indexの上位5個の単語を返す\n",
    "f_word.iloc[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d = 1\n",
    "word  \n",
    "469627\t本條流  \n",
    "462208\t今牛若丸  \n",
    "354733\tメーモ  \n",
    "350894\t唐家  \n",
    "467066\t茂山千五郎家  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d = 2\n",
    "\n",
    "word  \n",
    "177117\t松林宗恵  \n",
    "108168\tミケーレ・アルボレート  \n",
    "174178\t迎賓  \n",
    "179223\t斑鳩宮  \n",
    "181325\t近接作用  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d = 3\n",
    "\tword  \n",
    "185883\tチェイス・アトリー  \n",
    "57097\tウッチャンナンチャン  \n",
    "201471\t島村宜伸  \n",
    "42906\t和田アキ子  \n",
    "202632\t9打  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d = 4\n",
    "\n",
    "word  \n",
    "125465\t筋骨  \n",
    "10769\tミックス  \n",
    "30399\t楽長  \n",
    "69885\t養成施設  \n",
    "108534\tサレジオ  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d = 30\n",
    "\n",
    "word  \n",
    "114101\tもう半分  \n",
    "94739\tマタタビ  \n",
    "33536\t227  \n",
    "75829\tキルギス共和国  \n",
    "92307\t上葉  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d = 50\n",
    "word  \n",
    "13667\t旧暦  \n",
    "47014\t徒歩圏内  \n",
    "90948\tドルトレヒト  \n",
    "65341\t1238年  \n",
    "27042\tおける  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d = 99\n",
    "word  \n",
    "73961\tサーベイヤー  \n",
    "143156\tアララト山  \n",
    "129667\t魔弾の射手  \n",
    "151606\t手練  \n",
    "76658\t2000枚  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# f_dimention = pd.DataFrame(list(var_per_dimention.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pdp.ProfileReport(f_dimention.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -----------ある単語の類似する単語を挙げる-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def checkSim_by_word(vecs, word):\n",
    "    # 閾値の設定\n",
    "    negative = False # Falseなら似た単語を候補で上げる\n",
    "    threshold = 0.5 # -1なら閾値固定\n",
    "    border_positive = threshold if threshold > 0 else 0.8\n",
    "    border_negative = threshold if threshold > 0 else 0.3\n",
    "\n",
    "    # 候補数の設定\n",
    "    max_candidates = 20\n",
    "    candidates = {}\n",
    "    \n",
    "    # wordの設定確認\n",
    "    if not word:\n",
    "        raise Exception(\"word is missing\")\n",
    "\n",
    "    # wordがモデルにない場合，\n",
    "    if word not in vecs:\n",
    "        raise Exception(\"Sorry, this word is not registered in model.\")\n",
    "\n",
    "    # ベクトルの設定\n",
    "    w_vec = vecs[word]\n",
    "    for w in vecs:\n",
    "        try:\n",
    "            if w_vec.shape != vecs[w].shape:\n",
    "                raise Exception(\"size not match\")\n",
    "            s = similarity(w_vec, vecs[w])\n",
    "        except Exception as ex:\n",
    "            print(w + \" is not valid word.\")\n",
    "            continue\n",
    "\n",
    "        if negative and s <= border_negative:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_negative -= 0.05\n",
    "        elif not negative and s >= border_positive:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_positive += 0.05\n",
    "\n",
    "        if len(candidates) > max_candidates:\n",
    "            break\n",
    "    \n",
    "    # 類義語算出\n",
    "    sorted_candidates = sorted(candidates, key=candidates.get, reverse=not negative)\n",
    "    for c in sorted_candidates:\n",
    "        print(\"{0}, {1}\".format(c, candidates[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word = 'on'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 初期vecの場合，\n",
    "checkSim_by_word(vecs_wordVecs, word)\n",
    "print(' ')\n",
    "# newvecの場合，\n",
    "checkSim_by_word(vecs_new_vec, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -----------WordSim評価-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# word2vec\n",
    "vecs_wordVecs = wordVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# newvec\n",
    "vecs_new_vec = new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def checkSim(v1, v2):\n",
    "    if v1 not in lexicon: # 注目単語がwordnetに含まれない場合，\n",
    "        print(\"v1(={})はwordnetのkeyに存在しません\".format(v1))\n",
    "        wordNeighbours_1 = set()\n",
    "    else:\n",
    "        # 注目単語の同義語リストとword2vecのkeyリストと重複する単語リスト（更新対象か？）\n",
    "        wordNeighbours_1 = set(lexicon[v1]).intersection(set(wordVecs.keys()))\n",
    "        print('v1(={})における更新対象のneighbour数 : {}'.format(v1, len(wordNeighbours_1)))\n",
    "        \n",
    "    # neighboursの中で注目単語と類似度が低いもの\n",
    "    ave_1_word2vec = np.zeros_like(wordVecs[v1])  #neighboursの平均ベクトル\n",
    "    ave_1_retrofit = np.zeros_like(wordVecs[v1])\n",
    "    for neighbour in wordNeighbours_1:\n",
    "        print('v1とneighbour(={}) : {} -> {}'.format(neighbour, \n",
    "                                                                   similarity(wordVecs[neighbour], wordVecs[v1]), \n",
    "                                                                   similarity(vecs_new_vec[neighbour], vecs_new_vec[v1])))\n",
    "        ave_1_word2vec += wordVecs[neighbour]\n",
    "        ave_1_retrofit += vecs_new_vec[neighbour]\n",
    "    print('v1とneighboursの平均ベクトル : {} -> {}'.format(similarity(ave_1_word2vec/len(wordNeighbours_1), wordVecs[v1]), \n",
    "                                                              similarity(ave_1_retrofit/len(wordNeighbours_1), vecs_new_vec[v1])))\n",
    "    print(\" \")\n",
    "    \n",
    "    if v2 not in lexicon:\n",
    "        print(\"v2(={})はwordnetのkeyに存在しません\".format(v2))\n",
    "        wordNeighbours_2 = set()\n",
    "    else:\n",
    "        wordNeighbours_2 = set(lexicon[v2]).intersection(set(wordVecs.keys()))\n",
    "        print('v2(={})における更新対象のneighbour数 : {}'.format(v2, len(wordNeighbours_2))) # 更新対象数\n",
    "    \n",
    "    # neighboursの中で注目単語と類似度が低いもの\n",
    "    ave_2_word2vec = np.zeros_like(wordVecs[v2])  #neighboursの平均ベクトル\n",
    "    ave_2_retrofit = np.zeros_like(wordVecs[v2])\n",
    "    for neighbour in wordNeighbours_2:\n",
    "        print('v2とneighbour(={}) : {} -> {}'.format(neighbour, \n",
    "                                                                   similarity(wordVecs[neighbour], wordVecs[v2]), \n",
    "                                                                   similarity(vecs_new_vec[neighbour], vecs_new_vec[v2])))\n",
    "        ave_2_word2vec += wordVecs[neighbour]\n",
    "        ave_2_retrofit += vecs_new_vec[neighbour]\n",
    "    print('v2とneighboursの平均ベクトル : {} -> {}'.format(similarity(ave_2_word2vec/len(wordNeighbours_2), wordVecs[v2]), \n",
    "                                                              similarity(ave_2_retrofit/len(wordNeighbours_2), vecs_new_vec[v2])))\n",
    "    print(\" \")\n",
    "    \n",
    "    # v1とv2における更新対象のneighbourに重複があるか\n",
    "    print('更新対象における重複 : {}'.format(set(wordNeighbours_1).intersection(set(wordNeighbours_2))))\n",
    "    print('更新対象における重複数 : {}'.format(len(set(wordNeighbours_1).intersection(set(wordNeighbours_2)))))\n",
    "    print(\" \")\n",
    "\n",
    "    \"\"\"v1とv2のword2vecとretrofittingにおける類似度\"\"\"\n",
    "    try:\n",
    "        print(\"word2vec : {}\".format(similarity(vecs_wordVecs[v1], vecs_wordVecs[v2])))\n",
    "    except:\n",
    "        print('error')\n",
    "\n",
    "    try:\n",
    "        print(\"retrofitting : {}\".format(similarity(vecs_new_vec[v1], vecs_new_vec[v2])))\n",
    "    except:\n",
    "        print('error')\n",
    "\n",
    "    print(\" \")\n",
    "    \"\"\"同一単語におけるword2vecとretrofittingの類似度\"\"\"\n",
    "    try:\n",
    "        print(\"v1 : {}\".format(similarity(vecs_wordVecs[v1], vecs_new_vec[v1])))\n",
    "    except:\n",
    "        print('error')\n",
    "\n",
    "    try:\n",
    "        print(\"v2 : {}\".format(similarity(vecs_wordVecs[v2], vecs_new_vec[v2])))\n",
    "    except:\n",
    "        print('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ・WordSimのテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v1 = 'フットボール'\n",
    "v2 = 'サッカー'\n",
    "# checkSim(v1, v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -----------wordAnalogy評価-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def checkAnalogy(vecs, w_vec):  \n",
    "    negative = False # Falseなら似た単語を候補で上げる\n",
    "    threshold = 0.3 # -1なら閾値固定\n",
    "\n",
    "    # 閾値の設定\n",
    "    border_positive = threshold if threshold > 0 else 0.9\n",
    "    border_negative = threshold if threshold > 0 else 0.2\n",
    "    print('{} < thd < {}'.format(border_negative, border_positive))\n",
    "\n",
    "    # 候補数の設定\n",
    "    max_candidates = 20\n",
    "    candidates = {}\n",
    "\n",
    "    for w in vecs:\n",
    "        try:\n",
    "            if w_vec.shape != vecs[w].shape:\n",
    "                raise Exception(\"size not match\")\n",
    "            s = similarity(w_vec, vecs[w])\n",
    "        except Exception as ex:\n",
    "            print(w + \" is not valid word.\")\n",
    "            continue\n",
    "\n",
    "        if negative and s <= border_negative:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_negative -= 0.05\n",
    "        elif not negative and s >= border_positive:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_positive += 0.05\n",
    "\n",
    "        if len(candidates) > max_candidates:\n",
    "            break\n",
    "\n",
    "    # 類義語算出\n",
    "    sorted_candidates = sorted(candidates, key=candidates.get, reverse=not negative)\n",
    "    for c in sorted_candidates:\n",
    "        print(\"{0}, {1}\".format(c, candidates[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ・「v1 + v2 - v3」と「v4」の類似度算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "v1 = '兄'\n",
    "v2 = '姉'\n",
    "v3 = '祖父'\n",
    "v4 = '祖母'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if v1 not in lexicon:\n",
    "    print(\"v1 not found error in dict\")\n",
    "if v2 not in lexicon:\n",
    "    print(\"v2 not found error in dict\")\n",
    "if v3 not in lexicon:\n",
    "    print(\"v3 not found error in dict\")\n",
    "if v4 not in lexicon:\n",
    "    print(\"v4 not found error in dict\")\n",
    "\n",
    "try:\n",
    "    print('word2vec : {}'.format(similarity(vecs_wordVecs[v1] + vecs_wordVecs[v2] - vecs_wordVecs[v3], vecs_wordVecs[v4])))\n",
    "except:\n",
    "    print('error')\n",
    "\n",
    "try:\n",
    "    print('retrofitting : {}'.format(similarity(vecs_new_vec[v1] + vecs_new_vec[v2] - vecs_new_vec[v3], vecs_new_vec[v4])))\n",
    "except:\n",
    "    print('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ・「v1 + v2 - v3」と近い単語を挙げる→「v4」が結果に出るか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 初期vecの場合，\n",
    "checkAnalogy(vecs_wordVecs, vecs_wordVecs[v1] + vecs_wordVecs[v2] - vecs_wordVecs[v3])\n",
    "print(' ')\n",
    "# newvecの場合，\n",
    "checkAnalogy(vecs_new_vec, vecs_new_vec[v1] + vecs_new_vec[v2] - vecs_new_vec[v3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
