{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 定性評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -----------初期設定-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# python3\n",
    "#\n",
    "import argparse\n",
    "import gzip\n",
    "import math\n",
    "import numpy\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import codecs\n",
    "from statistics import mean, median,variance,stdev\n",
    "import pandas as pd\n",
    "import pandas_profiling as pdp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "newvec = joblib.load(\"/Users/1-10robotics/Desktop/Sparse_Overcomplete/P_ver/trained_model/numIter = 7-15_l1_reg = 0.5_l2_reg = 1e-5_factor = 3_rate = 0.05_learning rate/newvec_7.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# isNumber = re.compile(r'\\d+.*')\n",
    "# def norm_word(word):\n",
    "#     if isNumber.search(word.lower()):\n",
    "#         return '---num---'\n",
    "#     elif re.sub(r'\\W+', '', word) == '':\n",
    "#         return '---punc---'\n",
    "#     else:\n",
    "#         return word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"vectorsのread + normalize\"\"\"\n",
    "# def ReadVecsFromFile(filename):\n",
    "#     wordVectors = {}\n",
    "#     # ファイル読み込み\n",
    "#     if filename.endswith('.gz'):\n",
    "#         fileObject = gzip.open(filename, 'r')\n",
    "#     else:\n",
    "#         fileObject = codecs.open(filename, \"r\", \"utf-8\", 'ignore')\n",
    "\n",
    "#     for line in fileObject:\n",
    "#         # line = line.strip().lower()\n",
    "#         line = line.strip()\n",
    "#         word = line.split()[0]\n",
    "#         wordVectors[word] = np.zeros(len(line.split())-1, dtype=float)  # (L,)\n",
    "#         for index, vecVal in enumerate(line.split()[1:]):\n",
    "#             wordVectors[word][index] = float(vecVal)\n",
    "#         \"\"\"normalize weight vector\"\"\"\n",
    "#         wordVectors[word] /= [math.sqrt((wordVectors[word]**2).sum() + 1e-6)]\n",
    "#         wordVectors[word] = np.array([wordVectors[word]]) # (1, L)\n",
    "\n",
    "#     sys.stderr.write(\"Vectors read from: \"+filename+\" \\n\")\n",
    "#     return wordVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"vectorsのread + normalize\"\"\"\n",
    "# def ReadVecsFromFile_non(filename):\n",
    "#     wordVectors = {}\n",
    "#     # ファイル読み込み\n",
    "#     if filename.endswith('.gz'):\n",
    "#         fileObject = gzip.open(filename, 'r')\n",
    "#     else:\n",
    "#         fileObject = codecs.open(filename, \"r\", \"utf-8\", 'ignore')\n",
    "\n",
    "#     for line in fileObject:\n",
    "#         # line = line.strip().lower()\n",
    "#         line = line.strip()\n",
    "#         word = line.split()[0]\n",
    "#         wordVectors[word] = np.zeros(len(line.split())-1, dtype=float)  # (L,)\n",
    "#         for index, vecVal in enumerate(line.split()[1:]):\n",
    "#             wordVectors[word][index] = float(vecVal)\n",
    "# #         \"\"\"normalize weight vector\"\"\"\n",
    "# #         wordVectors[word] /= [math.sqrt((wordVectors[word]**2).sum() + 1e-6)]\n",
    "# #         wordVectors[word] = np.array([wordVectors[word]]) # (1, L)\n",
    "\n",
    "#     sys.stderr.write(\"Vectors read from: \"+filename+\" \\n\")\n",
    "#     return wordVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"vector A の書き込み\"\"\"\n",
    "# def WriteVectorsToFile(newvec, outFileName):\n",
    "#     \"\"\"Write word vectors to file\"\"\"\n",
    "#     sys.stderr.write('\\nWriting down the vectors in '+outFileName+'\\n')\n",
    "#     outFile = open(outFileName, 'w')\n",
    "#     for word in newvec.keys():\n",
    "#         outFile.write(word+' ')\n",
    "#         for val in newvec[word][0]:\n",
    "#             outFile.write('%.4f' % (val)+' ')\n",
    "#         outFile.write('\\n')\n",
    "#     outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# def similarity(v1, v2):\n",
    "#     n1 = np.linalg.norm(v1) # v1のノルム\n",
    "#     n2 = np.linalg.norm(v2) # v2のノルム\n",
    "#     return np.dot(v1, v2) / (n1*n2) # 内積 / "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Qualitative_Evaluation（各次元の外れ値（ =分散が大きい）の単語Top5）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 単語ベクトル\n",
    "newvec_word = list(newvec.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# wordをidで対応づけるためのdataframe\n",
    "f_word = pd.DataFrame(newvec_word, columns=['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 分散ベクトル\n",
    "newvec_dimention = list(newvec.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# limitまでの次元まで (全単語の100次元までを集計)\n",
    "# valueを保存する\n",
    "var_per_dimention = {}\n",
    "limit_num = 100\n",
    "for v in range(len(newvec_dimention)):\n",
    "    for j in range(len(newvec_dimention[v][0])):\n",
    "        if j < limit_num:\n",
    "            try:\n",
    "                var_per_dimention[j].append(newvec_dimention[v][0][j])\n",
    "            except:\n",
    "                var_per_dimention[j] = [newvec_dimention[v][0][j]]\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 単語操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 次元ごとに0占有率に関するリストを作成する\n",
    "memo_80min = []\n",
    "memo_80 = []\n",
    "memo_85 = []\n",
    "memo_90 = []\n",
    "memo_95 = []\n",
    "memo_96 = []\n",
    "memo_97 = []\n",
    "memo_98 = []\n",
    "memo_99 = []\n",
    "memo_other = []\n",
    "for i in range(len(list(var_per_dimention.values()))):\n",
    "    x = list(var_per_dimention.values())[i]\n",
    "    if (x.count(0) / len(x)) * 100 < 80:\n",
    "        memo_80min.append(i)\n",
    "    elif(x.count(0) / len(x)) * 100 < 85:\n",
    "        memo_80.append(i)\n",
    "    elif (x.count(0) / len(x)) * 100 < 90:\n",
    "        memo_85.append(i)\n",
    "    elif (x.count(0) / len(x)) * 100 < 95:\n",
    "        memo_90.append(i)\n",
    "    elif (x.count(0) / len(x)) * 100 < 96:\n",
    "        memo_95.append(i)\n",
    "    elif (x.count(0) / len(x)) * 100 < 97:\n",
    "        memo_96.append(i)\n",
    "    elif (x.count(0) / len(x)) * 100 < 98:\n",
    "        memo_97.append(i)\n",
    "    elif (x.count(0) / len(x)) * 100 < 99:\n",
    "        memo_98.append(i)\n",
    "    elif (x.count(0) / len(x)) * 100 < 100:\n",
    "        memo_99.append(i)\n",
    "    else:\n",
    "        memo_other.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~80: [0, 5, 8, 14, 19, 24, 25, 31, 35, 37, 45, 48, 49, 50, 51, 55, 58, 59, 63, 64, 67, 74, 83, 86, 91, 93, 94, 96, 99]\n",
      "80~85: [1, 7, 13, 27, 38, 42, 66, 68, 71, 75]\n",
      "85~90: [10, 17, 18, 20, 26, 29, 34, 46, 56, 69, 95, 97]\n",
      "90~95: [3, 21, 30, 54]\n",
      "95: [6, 28, 52, 81, 84]\n",
      "96: [4, 11, 23, 82, 98]\n",
      "97: [22, 33, 41]\n",
      "98: [2, 15, 32, 40, 47, 53, 57, 60, 61, 70, 73, 79, 80, 85, 89, 90, 92]\n",
      "99: [9, 12, 16, 36, 39, 43, 44, 62, 65, 72, 76, 77, 78, 87, 88]\n",
      "other: []\n"
     ]
    }
   ],
   "source": [
    "print(\"~80: {}\".format(memo_80min))\n",
    "print(\"80~85: {}\".format(memo_80))\n",
    "print(\"85~90: {}\".format(memo_85))\n",
    "print(\"90~95: {}\".format(memo_90))\n",
    "print(\"95: {}\".format(memo_95))\n",
    "print(\"96: {}\".format(memo_96))\n",
    "print(\"97: {}\".format(memo_97))\n",
    "print(\"98: {}\".format(memo_98))\n",
    "print(\"99: {}\".format(memo_99))\n",
    "print(\"other: {}\".format(memo_other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[memo_99] d: 9, mean: 0.0018949508666992188\n",
      "\n",
      "[memo_99] d: 9, max: 3.41015625\n",
      "\n",
      "[memo_99] d: 9, target_word:          word\n",
      "62999   国道23号\n",
      "59305   divid\n",
      "323299  西高野街道\n",
      "320561   日開野町\n",
      "311274    縁上回\n",
      "327638  小杉御殿町\n",
      "651495   初富本町\n",
      "320838    日向町\n",
      "649388     婁山\n",
      "651778     岩満\n",
      "\n",
      "[memo_99] d: 12, mean: 0.0115814208984375\n",
      "\n",
      "[memo_99] d: 12, max: 3.32421875\n",
      "\n",
      "[memo_99] d: 12, target_word:                word\n",
      "139767          添上郡\n",
      "49466           ツバキ\n",
      "135774      GOLDWIN\n",
      "26041   ローマ・カトリック教会\n",
      "136858          アダル\n",
      "35413      ロッテオリオンズ\n",
      "15233       モデルチェンジ\n",
      "137615          お答え\n",
      "16530          リターン\n",
      "33149          鍵盤楽器\n",
      "\n",
      "[memo_99] d: 16, mean: 0.0012979507446289062\n",
      "\n",
      "[memo_99] d: 16, max: 2.966796875\n",
      "\n",
      "[memo_99] d: 16, target_word:              word\n",
      "64386        JpnI\n",
      "60602         安八郡\n",
      "62101    大阪府大阪市北区\n",
      "65767         羽島郡\n",
      "67250     グリーティング\n",
      "59657     岐阜県各務原市\n",
      "64717     岐阜県中津川市\n",
      "62841         HAT\n",
      "63023      大分県佐伯市\n",
      "506207  リーフェンハウザー\n",
      "\n",
      "[memo_99] d: 36, mean: 0.01039886474609375\n",
      "\n",
      "[memo_99] d: 36, max: 3.609375\n",
      "\n",
      "[memo_99] d: 36, target_word:                word\n",
      "35485  ロサンゼルス・エンゼルス\n",
      "50591          選挙対策\n",
      "72545          方面総監\n",
      "43276         ペルージャ\n",
      "68225          無限遠点\n",
      "81933          政治生命\n",
      "66792        舞鶴海軍工廠\n",
      "72887            選対\n",
      "40725     アーリーエントリー\n",
      "73440            純増\n",
      "\n",
      "[memo_99] d: 39, mean: 0.0013818740844726562\n",
      "\n",
      "[memo_99] d: 39, max: 2.400390625\n",
      "\n",
      "[memo_99] d: 39, target_word:                word\n",
      "252929         広川弘禅\n",
      "11124             徐\n",
      "249793      ルーディメンツ\n",
      "103114            捨\n",
      "226950  ゲオルギ・ディミトロフ\n",
      "142022         一石二鳥\n",
      "192018          わんこ\n",
      "177505        ウナラスカ\n",
      "186366         稲荷大神\n",
      "161425           煥章\n",
      "\n",
      "[memo_99] d: 43, mean: 0.01088714599609375\n",
      "\n",
      "[memo_99] d: 43, max: 3.2421875\n",
      "\n",
      "[memo_99] d: 43, target_word:              word\n",
      "124748      山梨学院大\n",
      "40525      リアス式海岸\n",
      "23063    ガンダムシリーズ\n",
      "47459     ヴィータウタス\n",
      "49431      シェルブール\n",
      "35953      ローカライズ\n",
      "20176          山系\n",
      "123349         ドゥ\n",
      "50892          献花\n",
      "122490  大相撲野球賭博問題\n",
      "\n",
      "[memo_99] d: 44, mean: 0.0018377304077148438\n",
      "\n",
      "[memo_99] d: 44, max: 3.17578125\n",
      "\n",
      "[memo_99] d: 44, target_word:              word\n",
      "31665          漆器\n",
      "28044          勧進\n",
      "28465   プロテスタント教会\n",
      "216651       難太平記\n",
      "15660          捧ぐ\n",
      "26822        分離集落\n",
      "25481      フランス映画\n",
      "499969   フランボワイヤン\n",
      "215727  ハンス・メムリンク\n",
      "415889     チュッチェフ\n",
      "\n",
      "[memo_99] d: 62, mean: 0.0136260986328125\n",
      "\n",
      "[memo_99] d: 62, max: 3.21484375\n",
      "\n",
      "[memo_99] d: 62, target_word:                   word\n",
      "269348              弓月\n",
      "46158               pm\n",
      "44162   レークプラシッドオリンピック\n",
      "44814             1656\n",
      "257493        スペースデザイン\n",
      "259059             内田良\n",
      "48783            ストラット\n",
      "269171         エデンの園配置\n",
      "277539           88式鉄帽\n",
      "270933              ニム\n",
      "\n",
      "[memo_99] d: 65, mean: 0.0007190704345703125\n",
      "\n",
      "[memo_99] d: 65, max: 2.86328125\n",
      "\n",
      "[memo_99] d: 65, target_word:          word\n",
      "435563  如何わしい\n",
      "435687     乞四\n",
      "456723     成規\n",
      "425587  乗りかける\n",
      "682616     小丹\n",
      "448440     保生\n",
      "401783     富城\n",
      "463546     胡軍\n",
      "420837      迭\n",
      "452339      彈\n",
      "\n",
      "[memo_99] d: 72, mean: 0.0214385986328125\n",
      "\n",
      "[memo_99] d: 72, max: 3.375\n",
      "\n",
      "[memo_99] d: 72, target_word:                 word\n",
      "61110             安岡\n",
      "81566           規定違反\n",
      "67261     グレートブリテン貴族\n",
      "64671           オルソン\n",
      "718227  jurisdiction\n",
      "41599            烏帽子\n",
      "50924          DEATH\n",
      "78097           文理大学\n",
      "75635             次号\n",
      "48902              僚\n",
      "\n",
      "[memo_99] d: 76, mean: 0.011688232421875\n",
      "\n",
      "[memo_99] d: 76, max: 3.23046875\n",
      "\n",
      "[memo_99] d: 76, target_word:             word\n",
      "11858         普遍\n",
      "119416    アカルナニア\n",
      "9337      パンタグラフ\n",
      "66091    北関東自動車道\n",
      "140696       欧州旗\n",
      "149858        鈍角\n",
      "138117       本庄町\n",
      "142425  ランペドゥーザ島\n",
      "142917     キム・テヒ\n",
      "8248          寸法\n",
      "\n",
      "[memo_99] d: 77, mean: 0.0016498565673828125\n",
      "\n",
      "[memo_99] d: 77, max: 3.30078125\n",
      "\n",
      "[memo_99] d: 77, target_word:           word\n",
      "333992   48.1%\n",
      "95415      942\n",
      "99093     スズケン\n",
      "510826   65.8%\n",
      "93332   Oxygen\n",
      "343131     IOP\n",
      "95389     8.5%\n",
      "94676       浦川\n",
      "103535     882\n",
      "93157      SIC\n",
      "\n",
      "[memo_99] d: 78, mean: 0.0171356201171875\n",
      "\n",
      "[memo_99] d: 78, max: 3.41796875\n",
      "\n",
      "[memo_99] d: 78, target_word:                  word\n",
      "23890            参勤交代\n",
      "135310             青池\n",
      "68195              二又\n",
      "79210   カトリーヌ・ド・メディシス\n",
      "55610          住友グループ\n",
      "68151             美術商\n",
      "85396              洗馬\n",
      "532191           上石津郡\n",
      "60668           高層建築物\n",
      "48865             知恩院\n",
      "\n",
      "[memo_99] d: 87, mean: 0.00437164306640625\n",
      "\n",
      "[memo_99] d: 87, max: 3.296875\n",
      "\n",
      "[memo_99] d: 87, target_word:             word\n",
      "56260       リオ五輪\n",
      "52623      MISIA\n",
      "60406     桃山学院大学\n",
      "54052         投句\n",
      "59487         丸藤\n",
      "60829         怒涛\n",
      "59951      canbe\n",
      "61482        天王山\n",
      "61457       委託販売\n",
      "69925  レッスルキングダム\n",
      "\n",
      "[memo_99] d: 88, mean: 0.007709503173828125\n",
      "\n",
      "[memo_99] d: 88, max: 3.12109375\n",
      "\n",
      "[memo_99] d: 88, target_word:                   word\n",
      "265848              藻塩\n",
      "336144           ワースリー\n",
      "266402             BIN\n",
      "269369            ヌーベル\n",
      "273984  フランツ・アントン・メスメル\n",
      "279937             \"\"》\n",
      "393233           Anglo\n",
      "501210              リビ\n",
      "265180        フレッド・ローズ\n",
      "276630    リオデジャネイロ連邦大学\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 特定の次元の平均を求める\n",
    "for d in memo_99:\n",
    "    # i番目の次元のベクトルに注目\n",
    "    x = list(var_per_dimention.values())[d]\n",
    "    # 平均を求める\n",
    "    mean_x = np.average(x)\n",
    "    print(\"[memo_99] d: {}, mean: {}\\n\".format(d, mean_x))\n",
    "\n",
    "    # 求めた平均から各単語の分散を求める\n",
    "    var_x = [math.sqrt((mean_x - x[i]) ** 2) for i in range(len(x))]\n",
    "\n",
    "    # 分散の大きさ順にソートし，indexを返す\n",
    "    index_x_sorted = sorted(\n",
    "        range(len(var_x)), key=lambda k: var_x[k], reverse=True\n",
    "    )\n",
    "    \n",
    "    print(\"[memo_99] d: {}, max: {}\\n\".format(d, sorted(var_x, reverse=True)[0]))\n",
    "\n",
    "    # indexの上位5個\n",
    "    target = index_x_sorted[:10]\n",
    "    print(\"[memo_99] d: {}, target_word: {}\\n\".format(d, f_word.iloc[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -----------ある単語の類似する単語を挙げる-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def checkSim_by_word(vecs, word):\n",
    "    # 閾値の設定\n",
    "    negative = False # Falseなら似た単語を候補で上げる\n",
    "    threshold = 0.5 # -1なら閾値固定\n",
    "    border_positive = threshold if threshold > 0 else 0.8\n",
    "    border_negative = threshold if threshold > 0 else 0.3\n",
    "\n",
    "    # 候補数の設定\n",
    "    max_candidates = 20\n",
    "    candidates = {}\n",
    "    \n",
    "    # wordの設定確認\n",
    "    if not word:\n",
    "        raise Exception(\"word is missing\")\n",
    "\n",
    "    # wordがモデルにない場合，\n",
    "    if word not in vecs:\n",
    "        raise Exception(\"Sorry, this word is not registered in model.\")\n",
    "\n",
    "    # ベクトルの設定\n",
    "    w_vec = vecs[word]\n",
    "    for w in vecs:\n",
    "        try:\n",
    "            if w_vec.shape != vecs[w].shape:\n",
    "                raise Exception(\"size not match\")\n",
    "            s = similarity(w_vec, vecs[w])\n",
    "        except Exception as ex:\n",
    "            print(w + \" is not valid word.\")\n",
    "            continue\n",
    "\n",
    "        if negative and s <= border_negative:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_negative -= 0.05\n",
    "        elif not negative and s >= border_positive:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_positive += 0.05\n",
    "\n",
    "        if len(candidates) > max_candidates:\n",
    "            break\n",
    "    \n",
    "    # 類義語算出\n",
    "    sorted_candidates = sorted(candidates, key=candidates.get, reverse=not negative)\n",
    "    for c in sorted_candidates:\n",
    "        print(\"{0}, {1}\".format(c, candidates[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word = 'on'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 初期vecの場合，\n",
    "checkSim_by_word(vecs_wordVecs, word)\n",
    "print(' ')\n",
    "# newvecの場合，\n",
    "checkSim_by_word(vecs_new_vec, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -----------WordSim評価-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# word2vec\n",
    "vecs_wordVecs = wordVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# newvec\n",
    "vecs_new_vec = new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def checkSim(v1, v2):\n",
    "    if v1 not in lexicon: # 注目単語がwordnetに含まれない場合，\n",
    "        print(\"v1(={})はwordnetのkeyに存在しません\".format(v1))\n",
    "        wordNeighbours_1 = set()\n",
    "    else:\n",
    "        # 注目単語の同義語リストとword2vecのkeyリストと重複する単語リスト（更新対象か？）\n",
    "        wordNeighbours_1 = set(lexicon[v1]).intersection(set(wordVecs.keys()))\n",
    "        print('v1(={})における更新対象のneighbour数 : {}'.format(v1, len(wordNeighbours_1)))\n",
    "        \n",
    "    # neighboursの中で注目単語と類似度が低いもの\n",
    "    ave_1_word2vec = np.zeros_like(wordVecs[v1])  #neighboursの平均ベクトル\n",
    "    ave_1_retrofit = np.zeros_like(wordVecs[v1])\n",
    "    for neighbour in wordNeighbours_1:\n",
    "        print('v1とneighbour(={}) : {} -> {}'.format(neighbour, \n",
    "                                                                   similarity(wordVecs[neighbour], wordVecs[v1]), \n",
    "                                                                   similarity(vecs_new_vec[neighbour], vecs_new_vec[v1])))\n",
    "        ave_1_word2vec += wordVecs[neighbour]\n",
    "        ave_1_retrofit += vecs_new_vec[neighbour]\n",
    "    print('v1とneighboursの平均ベクトル : {} -> {}'.format(similarity(ave_1_word2vec/len(wordNeighbours_1), wordVecs[v1]), \n",
    "                                                              similarity(ave_1_retrofit/len(wordNeighbours_1), vecs_new_vec[v1])))\n",
    "    print(\" \")\n",
    "    \n",
    "    if v2 not in lexicon:\n",
    "        print(\"v2(={})はwordnetのkeyに存在しません\".format(v2))\n",
    "        wordNeighbours_2 = set()\n",
    "    else:\n",
    "        wordNeighbours_2 = set(lexicon[v2]).intersection(set(wordVecs.keys()))\n",
    "        print('v2(={})における更新対象のneighbour数 : {}'.format(v2, len(wordNeighbours_2))) # 更新対象数\n",
    "    \n",
    "    # neighboursの中で注目単語と類似度が低いもの\n",
    "    ave_2_word2vec = np.zeros_like(wordVecs[v2])  #neighboursの平均ベクトル\n",
    "    ave_2_retrofit = np.zeros_like(wordVecs[v2])\n",
    "    for neighbour in wordNeighbours_2:\n",
    "        print('v2とneighbour(={}) : {} -> {}'.format(neighbour, \n",
    "                                                                   similarity(wordVecs[neighbour], wordVecs[v2]), \n",
    "                                                                   similarity(vecs_new_vec[neighbour], vecs_new_vec[v2])))\n",
    "        ave_2_word2vec += wordVecs[neighbour]\n",
    "        ave_2_retrofit += vecs_new_vec[neighbour]\n",
    "    print('v2とneighboursの平均ベクトル : {} -> {}'.format(similarity(ave_2_word2vec/len(wordNeighbours_2), wordVecs[v2]), \n",
    "                                                              similarity(ave_2_retrofit/len(wordNeighbours_2), vecs_new_vec[v2])))\n",
    "    print(\" \")\n",
    "    \n",
    "    # v1とv2における更新対象のneighbourに重複があるか\n",
    "    print('更新対象における重複 : {}'.format(set(wordNeighbours_1).intersection(set(wordNeighbours_2))))\n",
    "    print('更新対象における重複数 : {}'.format(len(set(wordNeighbours_1).intersection(set(wordNeighbours_2)))))\n",
    "    print(\" \")\n",
    "\n",
    "    \"\"\"v1とv2のword2vecとretrofittingにおける類似度\"\"\"\n",
    "    try:\n",
    "        print(\"word2vec : {}\".format(similarity(vecs_wordVecs[v1], vecs_wordVecs[v2])))\n",
    "    except:\n",
    "        print('error')\n",
    "\n",
    "    try:\n",
    "        print(\"retrofitting : {}\".format(similarity(vecs_new_vec[v1], vecs_new_vec[v2])))\n",
    "    except:\n",
    "        print('error')\n",
    "\n",
    "    print(\" \")\n",
    "    \"\"\"同一単語におけるword2vecとretrofittingの類似度\"\"\"\n",
    "    try:\n",
    "        print(\"v1 : {}\".format(similarity(vecs_wordVecs[v1], vecs_new_vec[v1])))\n",
    "    except:\n",
    "        print('error')\n",
    "\n",
    "    try:\n",
    "        print(\"v2 : {}\".format(similarity(vecs_wordVecs[v2], vecs_new_vec[v2])))\n",
    "    except:\n",
    "        print('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ・WordSimのテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v1 = 'フットボール'\n",
    "v2 = 'サッカー'\n",
    "# checkSim(v1, v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -----------wordAnalogy評価-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def checkAnalogy(vecs, w_vec):  \n",
    "    negative = False # Falseなら似た単語を候補で上げる\n",
    "    threshold = 0.3 # -1なら閾値固定\n",
    "\n",
    "    # 閾値の設定\n",
    "    border_positive = threshold if threshold > 0 else 0.9\n",
    "    border_negative = threshold if threshold > 0 else 0.2\n",
    "    print('{} < thd < {}'.format(border_negative, border_positive))\n",
    "\n",
    "    # 候補数の設定\n",
    "    max_candidates = 20\n",
    "    candidates = {}\n",
    "\n",
    "    for w in vecs:\n",
    "        try:\n",
    "            if w_vec.shape != vecs[w].shape:\n",
    "                raise Exception(\"size not match\")\n",
    "            s = similarity(w_vec, vecs[w])\n",
    "        except Exception as ex:\n",
    "            print(w + \" is not valid word.\")\n",
    "            continue\n",
    "\n",
    "        if negative and s <= border_negative:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_negative -= 0.05\n",
    "        elif not negative and s >= border_positive:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_positive += 0.05\n",
    "\n",
    "        if len(candidates) > max_candidates:\n",
    "            break\n",
    "\n",
    "    # 類義語算出\n",
    "    sorted_candidates = sorted(candidates, key=candidates.get, reverse=not negative)\n",
    "    for c in sorted_candidates:\n",
    "        print(\"{0}, {1}\".format(c, candidates[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ・「v1 + v2 - v3」と「v4」の類似度算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "v1 = '兄'\n",
    "v2 = '姉'\n",
    "v3 = '祖父'\n",
    "v4 = '祖母'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if v1 not in lexicon:\n",
    "    print(\"v1 not found error in dict\")\n",
    "if v2 not in lexicon:\n",
    "    print(\"v2 not found error in dict\")\n",
    "if v3 not in lexicon:\n",
    "    print(\"v3 not found error in dict\")\n",
    "if v4 not in lexicon:\n",
    "    print(\"v4 not found error in dict\")\n",
    "\n",
    "try:\n",
    "    print('word2vec : {}'.format(similarity(vecs_wordVecs[v1] + vecs_wordVecs[v2] - vecs_wordVecs[v3], vecs_wordVecs[v4])))\n",
    "except:\n",
    "    print('error')\n",
    "\n",
    "try:\n",
    "    print('retrofitting : {}'.format(similarity(vecs_new_vec[v1] + vecs_new_vec[v2] - vecs_new_vec[v3], vecs_new_vec[v4])))\n",
    "except:\n",
    "    print('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ・「v1 + v2 - v3」と近い単語を挙げる→「v4」が結果に出るか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 初期vecの場合，\n",
    "checkAnalogy(vecs_wordVecs, vecs_wordVecs[v1] + vecs_wordVecs[v2] - vecs_wordVecs[v3])\n",
    "print(' ')\n",
    "# newvecの場合，\n",
    "checkAnalogy(vecs_new_vec, vecs_new_vec[v1] + vecs_new_vec[v2] - vecs_new_vec[v3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
