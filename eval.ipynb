{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# wordSim評価\n",
    "# wordAnalogy評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -----------初期設定-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# python3\n",
    "#\n",
    "import argparse\n",
    "import gzip\n",
    "import math\n",
    "import numpy\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "isNumber = re.compile(r'\\d+.*')\n",
    "def norm_word(word):\n",
    "    if isNumber.search(word.lower()):\n",
    "        return '---num---'\n",
    "    elif re.sub(r'\\W+', '', word) == '':\n",
    "        return '---punc---'\n",
    "    else:\n",
    "        return word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Read all the word vectors and normalize them\"\"\"\n",
    "def read_word_vecs(filename):\n",
    "    wordVectors = {}\n",
    "    # ファイル読み込み\n",
    "    if filename.endswith('.gz'): \n",
    "        fileObject = gzip.open(filename, 'r')\n",
    "    else: \n",
    "        fileObject = codecs.open(filename, \"r\", \"utf-8\", 'ignore')\n",
    "        \n",
    "    for line in fileObject:\n",
    "        # line = line.strip().lower()\n",
    "        line = line.strip()\n",
    "        word = line.split()[0]\n",
    "        wordVectors[word] = numpy.zeros(len(line.split())-1, dtype=float)\n",
    "        for index, vecVal in enumerate(line.split()[1:]):\n",
    "            wordVectors[word][index] = float(vecVal)\n",
    "        \"\"\"normalize weight vector\"\"\"\n",
    "        wordVectors[word] /= math.sqrt((wordVectors[word]**2).sum() + 1e-7)\n",
    "\n",
    "    sys.stderr.write(\"Vectors read from: \"+filename+\" \\n\")\n",
    "    return wordVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Read all the word vectors and normalize them\"\"\"\n",
    "def read_word_vecs_non(filename):\n",
    "    wordVectors = {}\n",
    "    # ファイル読み込み\n",
    "    if filename.endswith('.gz'): \n",
    "        fileObject = gzip.open(filename, 'r')\n",
    "    else: \n",
    "        fileObject = codecs.open(filename, \"r\", \"utf-8\", 'ignore')\n",
    "        \n",
    "    for line in fileObject:\n",
    "        # line = line.strip().lower()\n",
    "        line = line.strip()\n",
    "        word = line.split()[0]\n",
    "        wordVectors[word] = numpy.zeros(len(line.split())-1, dtype=float)\n",
    "        for index, vecVal in enumerate(line.split()[1:]):\n",
    "            wordVectors[word][index] = float(vecVal)\n",
    "        \"\"\"normalize weight vector\"\"\"\n",
    "#         wordVectors[word] /= math.sqrt((wordVectors[word]**2).sum() + 1e-7)\n",
    "\n",
    "    sys.stderr.write(\"Vectors read from: \"+filename+\" \\n\")\n",
    "    return wordVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Write word vectors to file\"\"\"\n",
    "def print_word_vecs(wordVectors, outFileName):\n",
    "    sys.stderr.write('\\nWriting down the vectors in '+outFileName+'\\n')\n",
    "    outFile = open(outFileName, 'w')  \n",
    "    for word, values in wordVectors.items():\n",
    "        outFile.write(word+' ')\n",
    "        for val in wordVectors[word]:\n",
    "            outFile.write('%.4f' %(val)+' ')\n",
    "        outFile.write('\\n')      \n",
    "    outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Read the PPDB.etc word relations as a dictionary\"\"\"\n",
    "def read_lexicon(filename):\n",
    "    lexicon = {}\n",
    "    fileObject = open(filename, 'r')\n",
    "    for line in fileObject:\n",
    "        words = line.lower().strip().split()\n",
    "        lexicon[norm_word(words[0])] = [norm_word(word) for word in words[1:]]\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def similarity(v1, v2):\n",
    "    n1 = np.linalg.norm(v1) # v1のノルム\n",
    "    n2 = np.linalg.norm(v2) # v2のノルム\n",
    "    return np.dot(v1, v2) / (n1*n2) # 内積 / "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ・パス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# オリジナルの分散表現\n",
    "input_arg = './sample/sample_vecs.txt'\n",
    "# retrofittingしたnewvec\n",
    "output_arg = './sample/newvec.txt'\n",
    "output_arg_1 = './sample/newvec_non.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ・初期vecとnewvecとwordsim辞書のread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "outFileName = output_arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectors read from: ./sample/sample_vecs.txt \n"
     ]
    }
   ],
   "source": [
    "wordVecs = read_word_vecs(input_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectors read from: ./sample/newvec.txt \n"
     ]
    }
   ],
   "source": [
    "new_vec = read_word_vecs(output_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectors read from: ./sample/newvec_non.txt \n"
     ]
    }
   ],
   "source": [
    "new_vec_non = read_word_vecs_non(output_arg_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------各次元の分散が大きい単語top5-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statistics import variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def  Qualitative_Evaluation(vectors):\n",
    "    # 次元ごとの値を格納する\n",
    "    value_per_dimention = {}\n",
    "    for key in vectors.keys():\n",
    "        for j in range(len(vectors[key])):\n",
    "            try:\n",
    "                value_per_dimention[j] += [vectors[key][j]]\n",
    "            except:\n",
    "                value_per_dimention[j] = [vectors[key][j]]\n",
    "    \n",
    "    # 次元ごとに分散を計算する\n",
    "    var_per_dimention = []\n",
    "    for key in range(len(value_per_dimention.keys())):\n",
    "        var = variance(value_per_dimention[key])\n",
    "        var_per_dimention.append(var)\n",
    "    \n",
    "    # 分散が大きい上位5次元\n",
    "    top5_var = np.argsort(-np.array(var_per_dimention))[:5]\n",
    "    worst5_var = np.argsort(np.array(var_per_dimention))[:5]\n",
    "    print('分散が大きいtop5の次元 : {}'.format(top5_var))\n",
    "#     print('分散が小さいtop5の次元 : {}'.format(worst5_var))\n",
    "    print(\" \")\n",
    "    print(value_per_dimention[top5_var[0]])\n",
    "    print(\" \")\n",
    "    print(value_per_dimention[worst5_var[0]])\n",
    "    \n",
    "    print(\" \")\n",
    "    # top5の次元で大きい値の単語top5\n",
    "    for var in top5_var:\n",
    "        cnt = 0\n",
    "        top5_id = np.argsort(-np.array(value_per_dimention[var]))[:10]\n",
    "        print(\"{}次元のtop5の単語\".format(var))\n",
    "        for key in vectors.keys():\n",
    "            if cnt in top5_id:\n",
    "                print(key)\n",
    "            cnt += 1\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分散が大きいtop5の次元 : [ 84 110  14  22  42]\n",
      " \n",
      "[-0.041188563617448735, 0.0024033520297079276, -0.1050169586560986, 0.03710340335907547, 0.06733420776607296, -0.0631791105369332, 0.07828356080260786, -0.027740007510587954, 0.027922274818868702, 0.0025967566319395822, -0.07956504089898361, 0.01700037638041317, -0.10660092665852255, 0.03441858152022766, -0.0317711416556715, 0.05503710963572882, 0.04654471007945353, -0.07684494565332704, -0.02694488862135539, -0.03327638050329605, -0.01396007561487291, 0.013479415001757644, 0.042467467486799144, 0.024545383366806617, -0.07650318403674446, -0.03380191043464119, -0.024750055353817357, -0.06679460477238902, -0.08819207684311735, -0.05982059418074669, -0.05250198231592341, 0.00855522842868417, -0.028290623332081304, -0.009189475078995403, -0.030302306209432084, -0.1695535433702774, 0.07318426223607034, -0.005460272004753298, -0.04197614020255475, -0.09852796321943769, -0.08141770174604317, -0.057538037111713514, -0.04744812404393036, -0.1157429084241879, 0.010405409887136731, -0.02015223797174568, -0.10374440045126568, -0.006738431746518021, -0.056664798737899966, 0.010261475036981254, 0.04287098527883011, -0.054262860588456904, 0.0044838371558403155, -0.16849990465289852, -0.07489858716627967, -0.07302343202370969, -0.09264710450125203, 0.07011219692736528, -0.04800960486401845, -0.10960866514483283, -0.08752749779512407, 0.08954131453889981, 0.013464308942479663, -0.05187982904591652, -0.004638008854788936, -0.17540746431751614, -0.039761706039573755, -0.07984652694649973, -0.09695427412392302, -0.06135495567244613, -0.041367912445004304, -0.03574221540478111, -0.12464594467952947, -0.01851364303569908, -0.10800165077211725, -0.13626105157577922, -0.09469170217649704, -0.1180418723370823, -0.11382985934206404, -0.16393251634128198, -0.1515006734978873, 0.051176667692736745, -0.058772310285141495, 0.020042335540442397, 0.06391128577149437, 0.08276662389615574, -0.09787089921128296, -0.00021252103213071047, 0.03965716066258544, -0.0033004564974429204, -0.06012556058407423, 0.07016588395038464, 0.03014543626570184, 0.07870963557314885, -0.13461398568387298, 0.042891638560869215, 0.019627892507069488, 0.02131584822009095, 0.12354563456335538, 0.034537509427271566]\n",
      " \n",
      "[0.020318626924947555, -0.01781775536636743, -0.02912851070543291, 0.017124933834396845, -0.018052506393107744, -0.010413080591469866, 0.07264717007684297, -0.0576702516733934, 0.026029354232192874, -0.0332973841329069, 0.010780320082275929, -0.030132980675986448, -0.034310012142709054, 0.029446741761199657, -0.0808182426313865, -0.024883821893104226, 0.00017601685941648934, -0.007961926965762228, -0.00918545344624153, -0.07043445641465484, 0.06135326108779671, -0.016320183639810824, -0.054158065400704336, 0.006053208619752179, 0.0009602067644887569, 0.031900118431500604, 0.003235734061136032, -0.03027593371583147, 0.04465802419690256, -0.007878020247645482, 0.060854662977296484, -0.037517576165258214, 0.09313355648583768, -0.004071839909181078, 0.019527928149772063, -0.0022908017491109697, -0.009325050147965466, 0.009031305369533948, 0.03442046935303698, -0.06401810660208912, 0.06852640352525408, -0.033875071081010774, 0.06514478466435344, -0.017613163305011986, -0.08770216061104733, 0.011327941233124032, 0.029641257271790192, -0.026024813231184853, 0.08785665572741108, -0.04793081244613742, 0.023483412651038794, -0.02612637195329841, -0.009657083606403225, -0.050171537755854756, -0.025639380900262108, -0.0045303153199575345, 0.012683903732751165, 0.04507233009621078, 0.01646684241858102, -0.0064742367396398975, -0.06390925268384727, -0.0069886013120722765, -0.008193013452083696, -0.09122830337818755, -0.02364975328989018, -0.0398246772663673, 0.018614764780253878, 0.017770483818783163, -0.013138070058966871, -0.05964311851141932, -0.0178179823487754, 0.10204643049757364, -0.010248223376958007, 0.03450246337173957, -0.03558022457393259, -0.024558802414403808, 0.047988624434966, 0.0042421538247035635, -0.008448487184940099, 0.03795997381934176, -0.006598217410039323, -0.04016085554452471, -0.002721408054596802, 0.013045005354788673, 0.04152317247642488, -0.07129890070169057, -0.02404352778043202, 0.03660576992700507, -0.039915054825282494, -0.009590966530041697, -0.02112178285364036, 0.024420511445968265, 0.001363849581280822, -0.020965792104095875, 0.01730388826508166, -0.02314805286367331, -0.034468302853644446, -0.02258349132152044, 0.01803787214769663, -0.0005917147912498469]\n",
      " \n",
      "84次元のtop5の単語\n",
      "on\n",
      "with\n",
      "up\n",
      "new\n",
      "into\n",
      "game\n",
      "back\n",
      "team\n",
      "off\n",
      "second\n",
      " \n",
      "110次元のtop5の単語\n",
      "at\n",
      "more\n",
      "first\n",
      "than\n",
      "when\n",
      "what\n",
      "game\n",
      "now\n",
      "before\n",
      "second\n",
      " \n",
      "14次元のtop5の単語\n",
      "is\n",
      "was\n",
      "be\n",
      "has\n",
      "had\n",
      "been\n",
      "about\n",
      "than\n",
      "made\n",
      "through\n",
      " \n",
      "22次元のtop5の単語\n",
      "be\n",
      "i\n",
      "have\n",
      "will\n",
      "but\n",
      "we\n",
      "you\n",
      "so\n",
      "get\n",
      "make\n",
      " \n",
      "42次元のtop5の単語\n",
      "not\n",
      "i\n",
      "he\n",
      "you\n",
      "would\n",
      "when\n",
      "if\n",
      "did\n",
      "back\n",
      "off\n",
      " \n"
     ]
    }
   ],
   "source": [
    "Qualitative_Evaluation(wordVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分散が大きいtop5の次元 : [  69 2145 1157 1989 1844]\n",
      " \n",
      "[-0.027368007183783717, -0.028325058991896787, -0.029751978724367394, -0.03197102243404834, -0.033594829846398784, -0.03688731255742202, -0.0390599486444076, -0.04157409390535357, -0.04963555711138379, 0.02423755070107002, 0.020068642347818924, 0.01929271107714021, 0.018926809445226435, 0.01873805815746836, 0.018658086097636466, 0.018577724530984684, 0.018536339600633212, 0.018508855896844242, 0.018511799802759243, 0.018505902246792615, 0.01851398226366217, 0.018543683949226432, 0.01863297365998667, -0.018695656010012565, 0.018824742314480943, -0.01858474992154049, 0.018736073924059845, 0.019472434032926013, 0.017967287797045584, 0.019949179588974512, 0.01874826761195103, -0.01863880453445565, 0.018660566898797606, -0.01867629350290394, 0.018670547487414844, -0.01897132967642473, -0.019330411815342396, 0.018810022114927178, 0.019114670882843594, -0.018790432746739597, -0.01890688785380977, 0.0189221420284534, 0.01875110370423547, -0.018856769950560823, -0.019513383458722642, 0.018894707061359026, -0.018928974254626686, -0.018869150918702143, 0.01890750724484012, 0.02016330253795357, -0.019509892526364578, 0.018842658434724123, -0.018913798808082093, 0.019597623431055256, -0.018940787292192122, -0.019845774890256667, -0.02014139409979841, 0.019047964837288864, 0.019078725886486556, 0.0195902031904099, -0.01900190624934368, 0.019572727043233356, 0.019360588115897772, 0.019326106983982478, 0.019625557346161497, -0.01931043426334075, 0.01918886296239167, -0.019839362331107127, 0.019479219436863354, 0.019984195144432997, -0.019324722056795123, -0.019709316861137718, -0.019577415065812342, 0.01906001166108363, -0.019103636761274363, -0.019173551608346173, -0.019692114969538623, 0.02005457800972852, -0.01985746875532135, 0.01904681496230087, -0.019306548647424527, 0.01909922464503497, -0.01944226886592844, -0.019371240689178892, 0.019262443354019644, 0.019346903780944755, -0.02006628781022843, -0.019340553924826018, -0.019353267100275757, 0.01975789246708949, 0.019542581896187707, -0.01979990639138019, 0.010926128488677357, -0.019706145681096618, 0.019830768095630755, 0.019481767655082954, 0.019199869594059022, -0.019769356416834694, -0.019803976419791623, -0.01970983839033215]\n",
      " \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.013433371145598874, 0.01711888447689906, 0.01755860635280043, 0.01783682890740976, 0.018097221786084267, 0.017982045988909023, 0.017904841057124667, 0.017618650402807644, 0.017621452718057394, 0.017282065024058834, 0.016918589002464828, -0.009624878041782857, 0.0, 0.01745926994121414, 0.016749870917093266, -0.017504674274797658, -0.01712154250375008, 0.017862817510043014, 0.019854263227785534, -0.019422067120160143, -0.016043106754114408, -0.018041167515314788, 0.01787525246017085, 0.014035290708595147, 0.0, -0.013904689421475958, -0.01828026871873426, 0.0177168544970256, -0.018577310657221485, 0.0, -0.009263615735601576, -0.0008739141900691329, 0.017248009218926018, 0.0, 0.0, -0.017834483017835873, -0.013797625812107405, -0.007335902361178789, -0.01522471968911825, -0.01913874448216325, 0.019352554683410024, -0.017521029085595177, -0.018117827315156796, 0.019557464366647355, 0.01365410168252404, -0.01928220318951916, 0.01952482081102907, -0.018512479882023716, 0.0004597283346141339, 0.0, 0.01843070666269006, -0.018824473896711356, -0.01772448207793458, -0.01862616749562899, 0.019151700830761217, -0.01520018118720798, 0.012765299028286143, 0.01875721529486492, -0.019244057834003837, 0.019741962476015628, -0.018975480091913285, 0.019171037198963785, 0.01898654740789044, 0.011367115388236622, -0.014500350794702228, -0.019874520161769584, -0.01925539467787547, 0.019889179428204985, -0.01981627068736425, 0.01809064955254681, 0.0, -0.010470056883723992, 0.018346929774890216, 0.0, 0.018218094015548702, -0.017287895948836177, 0.0003700749801066719, 0.0, 0.008355326157749574, 0.01684997684189285, 0.017808965760235572, -0.018807844275736924, -0.019658753909552063, 0.0011124437078038412, 0.018668965520331173, -0.015421357133286717, -0.01831312862887156, 0.018973808874909757, 0.018963807723194403, -0.01954926944214207]\n",
      " \n",
      "69次元のtop5の単語\n",
      "at\n",
      "not\n",
      "but\n",
      "after\n",
      "than\n",
      "a\n",
      "some\n",
      "like\n",
      "company\n",
      "most\n",
      " \n",
      "2145次元のtop5の単語\n",
      "at\n",
      "not\n",
      "but\n",
      "after\n",
      "than\n",
      "some\n",
      "so\n",
      "against\n",
      "most\n",
      "state\n",
      " \n",
      "1157次元のtop5の単語\n",
      "at\n",
      "not\n",
      "after\n",
      "her\n",
      "could\n",
      "like\n",
      "company\n",
      "against\n",
      "most\n",
      "made\n",
      " \n",
      "1989次元のtop5の単語\n",
      "at\n",
      "not\n",
      "but\n",
      "her\n",
      "could\n",
      "some\n",
      "company\n",
      "against\n",
      "most\n",
      "made\n",
      " \n",
      "1844次元のtop5の単語\n",
      "at\n",
      "not\n",
      "after\n",
      "than\n",
      "her\n",
      "could\n",
      "so\n",
      "company\n",
      "most\n",
      "made\n",
      " \n"
     ]
    }
   ],
   "source": [
    "Qualitative_Evaluation(new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分散が大きいtop5の次元 : [ 369 1247 1241 2055 2059]\n",
      " \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]\n",
      " \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      " \n",
      "369次元のtop5の単語\n",
      "more\n",
      "you\n",
      "one\n",
      "would\n",
      "which\n",
      "out\n",
      "all\n",
      "after\n",
      "do\n",
      "than\n",
      " \n",
      "1247次元のtop5の単語\n",
      "more\n",
      "you\n",
      "one\n",
      "would\n",
      "which\n",
      "out\n",
      "all\n",
      "after\n",
      "first\n",
      "do\n",
      " \n",
      "1241次元のtop5の単語\n",
      "more\n",
      "you\n",
      "one\n",
      "would\n",
      "which\n",
      "out\n",
      "all\n",
      "after\n",
      "first\n",
      "do\n",
      " \n",
      "2055次元のtop5の単語\n",
      "more\n",
      "you\n",
      "one\n",
      "would\n",
      "which\n",
      "out\n",
      "all\n",
      "after\n",
      "do\n",
      "than\n",
      " \n",
      "2059次元のtop5の単語\n",
      "more\n",
      "you\n",
      "one\n",
      "would\n",
      "which\n",
      "out\n",
      "all\n",
      "after\n",
      "do\n",
      "than\n",
      " \n"
     ]
    }
   ],
   "source": [
    "Qualitative_Evaluation(new_vec_non)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word2vec_top5_dimention = [ 84, 110, 14, 22, 42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 次元ごとの値を格納する\n",
    "value_per_dimention = {}\n",
    "for key in new_vec.keys():\n",
    "    for j in range(len(new_vec[key])):\n",
    "        try:\n",
    "            value_per_dimention[j] += [new_vec[key][j]]\n",
    "        except:\n",
    "            value_per_dimention[j] = [new_vec[key][j]]\n",
    "            \n",
    "# top5の次元で大きい値の単語top5\n",
    "for var in word2vec_top5_dimention:\n",
    "    cnt = 0\n",
    "    top5_id = np.argsort(-np.array(value_per_dimention[var]))[:10]\n",
    "    print(\"{}次元のtop5の単語\".format(var))\n",
    "    for key in new_vec.keys():\n",
    "        if cnt in top5_id:\n",
    "            print(key)\n",
    "        cnt += 1\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -----------値の分散が最大な次元top5-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -----------ある単語の類似する単語を挙げる-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def checkSim_by_word(vecs, word):\n",
    "    # 閾値の設定\n",
    "    negative = False # Falseなら似た単語を候補で上げる\n",
    "    threshold = 0.5 # -1なら閾値固定\n",
    "    border_positive = threshold if threshold > 0 else 0.8\n",
    "    border_negative = threshold if threshold > 0 else 0.3\n",
    "\n",
    "    # 候補数の設定\n",
    "    max_candidates = 20\n",
    "    candidates = {}\n",
    "    \n",
    "    # wordの設定確認\n",
    "    if not word:\n",
    "        raise Exception(\"word is missing\")\n",
    "\n",
    "    # wordがモデルにない場合，\n",
    "    if word not in vecs:\n",
    "        raise Exception(\"Sorry, this word is not registered in model.\")\n",
    "\n",
    "    # ベクトルの設定\n",
    "    w_vec = vecs[word]\n",
    "    for w in vecs:\n",
    "        try:\n",
    "            if w_vec.shape != vecs[w].shape:\n",
    "                raise Exception(\"size not match\")\n",
    "            s = similarity(w_vec, vecs[w])\n",
    "        except Exception as ex:\n",
    "            print(w + \" is not valid word.\")\n",
    "            continue\n",
    "\n",
    "        if negative and s <= border_negative:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_negative -= 0.05\n",
    "        elif not negative and s >= border_positive:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_positive += 0.05\n",
    "\n",
    "        if len(candidates) > max_candidates:\n",
    "            break\n",
    "    \n",
    "    # 類義語算出\n",
    "    sorted_candidates = sorted(candidates, key=candidates.get, reverse=not negative)\n",
    "    for c in sorted_candidates:\n",
    "        print(\"{0}, {1}\".format(c, candidates[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word = 'on'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 初期vecの場合，\n",
    "checkSim_by_word(vecs_wordVecs, word)\n",
    "print(' ')\n",
    "# newvecの場合，\n",
    "checkSim_by_word(vecs_new_vec, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -----------WordSim評価-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# word2vec\n",
    "vecs_wordVecs = wordVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# newvec\n",
    "vecs_new_vec = new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def checkSim(v1, v2):\n",
    "    if v1 not in lexicon: # 注目単語がwordnetに含まれない場合，\n",
    "        print(\"v1(={})はwordnetのkeyに存在しません\".format(v1))\n",
    "        wordNeighbours_1 = set()\n",
    "    else:\n",
    "        # 注目単語の同義語リストとword2vecのkeyリストと重複する単語リスト（更新対象か？）\n",
    "        wordNeighbours_1 = set(lexicon[v1]).intersection(set(wordVecs.keys()))\n",
    "        print('v1(={})における更新対象のneighbour数 : {}'.format(v1, len(wordNeighbours_1)))\n",
    "        \n",
    "    # neighboursの中で注目単語と類似度が低いもの\n",
    "    ave_1_word2vec = np.zeros_like(wordVecs[v1])  #neighboursの平均ベクトル\n",
    "    ave_1_retrofit = np.zeros_like(wordVecs[v1])\n",
    "    for neighbour in wordNeighbours_1:\n",
    "        print('v1とneighbour(={}) : {} -> {}'.format(neighbour, \n",
    "                                                                   similarity(wordVecs[neighbour], wordVecs[v1]), \n",
    "                                                                   similarity(vecs_new_vec[neighbour], vecs_new_vec[v1])))\n",
    "        ave_1_word2vec += wordVecs[neighbour]\n",
    "        ave_1_retrofit += vecs_new_vec[neighbour]\n",
    "    print('v1とneighboursの平均ベクトル : {} -> {}'.format(similarity(ave_1_word2vec/len(wordNeighbours_1), wordVecs[v1]), \n",
    "                                                              similarity(ave_1_retrofit/len(wordNeighbours_1), vecs_new_vec[v1])))\n",
    "    print(\" \")\n",
    "    \n",
    "    if v2 not in lexicon:\n",
    "        print(\"v2(={})はwordnetのkeyに存在しません\".format(v2))\n",
    "        wordNeighbours_2 = set()\n",
    "    else:\n",
    "        wordNeighbours_2 = set(lexicon[v2]).intersection(set(wordVecs.keys()))\n",
    "        print('v2(={})における更新対象のneighbour数 : {}'.format(v2, len(wordNeighbours_2))) # 更新対象数\n",
    "    \n",
    "    # neighboursの中で注目単語と類似度が低いもの\n",
    "    ave_2_word2vec = np.zeros_like(wordVecs[v2])  #neighboursの平均ベクトル\n",
    "    ave_2_retrofit = np.zeros_like(wordVecs[v2])\n",
    "    for neighbour in wordNeighbours_2:\n",
    "        print('v2とneighbour(={}) : {} -> {}'.format(neighbour, \n",
    "                                                                   similarity(wordVecs[neighbour], wordVecs[v2]), \n",
    "                                                                   similarity(vecs_new_vec[neighbour], vecs_new_vec[v2])))\n",
    "        ave_2_word2vec += wordVecs[neighbour]\n",
    "        ave_2_retrofit += vecs_new_vec[neighbour]\n",
    "    print('v2とneighboursの平均ベクトル : {} -> {}'.format(similarity(ave_2_word2vec/len(wordNeighbours_2), wordVecs[v2]), \n",
    "                                                              similarity(ave_2_retrofit/len(wordNeighbours_2), vecs_new_vec[v2])))\n",
    "    print(\" \")\n",
    "    \n",
    "    # v1とv2における更新対象のneighbourに重複があるか\n",
    "    print('更新対象における重複 : {}'.format(set(wordNeighbours_1).intersection(set(wordNeighbours_2))))\n",
    "    print('更新対象における重複数 : {}'.format(len(set(wordNeighbours_1).intersection(set(wordNeighbours_2)))))\n",
    "    print(\" \")\n",
    "\n",
    "    \"\"\"v1とv2のword2vecとretrofittingにおける類似度\"\"\"\n",
    "    try:\n",
    "        print(\"word2vec : {}\".format(similarity(vecs_wordVecs[v1], vecs_wordVecs[v2])))\n",
    "    except:\n",
    "        print('error')\n",
    "\n",
    "    try:\n",
    "        print(\"retrofitting : {}\".format(similarity(vecs_new_vec[v1], vecs_new_vec[v2])))\n",
    "    except:\n",
    "        print('error')\n",
    "\n",
    "    print(\" \")\n",
    "    \"\"\"同一単語におけるword2vecとretrofittingの類似度\"\"\"\n",
    "    try:\n",
    "        print(\"v1 : {}\".format(similarity(vecs_wordVecs[v1], vecs_new_vec[v1])))\n",
    "    except:\n",
    "        print('error')\n",
    "\n",
    "    try:\n",
    "        print(\"v2 : {}\".format(similarity(vecs_wordVecs[v2], vecs_new_vec[v2])))\n",
    "    except:\n",
    "        print('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ・WordSimのテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v1 = 'フットボール'\n",
    "v2 = 'サッカー'\n",
    "# checkSim(v1, v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# -----------wordAnalogy評価-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def checkAnalogy(vecs, w_vec):  \n",
    "    negative = False # Falseなら似た単語を候補で上げる\n",
    "    threshold = 0.3 # -1なら閾値固定\n",
    "\n",
    "    # 閾値の設定\n",
    "    border_positive = threshold if threshold > 0 else 0.9\n",
    "    border_negative = threshold if threshold > 0 else 0.2\n",
    "    print('{} < thd < {}'.format(border_negative, border_positive))\n",
    "\n",
    "    # 候補数の設定\n",
    "    max_candidates = 20\n",
    "    candidates = {}\n",
    "\n",
    "    for w in vecs:\n",
    "        try:\n",
    "            if w_vec.shape != vecs[w].shape:\n",
    "                raise Exception(\"size not match\")\n",
    "            s = similarity(w_vec, vecs[w])\n",
    "        except Exception as ex:\n",
    "            print(w + \" is not valid word.\")\n",
    "            continue\n",
    "\n",
    "        if negative and s <= border_negative:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_negative -= 0.05\n",
    "        elif not negative and s >= border_positive:\n",
    "            candidates[w] = s\n",
    "            if len(candidates) % 5 == 0:\n",
    "                border_positive += 0.05\n",
    "\n",
    "        if len(candidates) > max_candidates:\n",
    "            break\n",
    "\n",
    "    # 類義語算出\n",
    "    sorted_candidates = sorted(candidates, key=candidates.get, reverse=not negative)\n",
    "    for c in sorted_candidates:\n",
    "        print(\"{0}, {1}\".format(c, candidates[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ・「v1 + v2 - v3」と「v4」の類似度算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "v1 = '兄'\n",
    "v2 = '姉'\n",
    "v3 = '祖父'\n",
    "v4 = '祖母'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if v1 not in lexicon:\n",
    "    print(\"v1 not found error in dict\")\n",
    "if v2 not in lexicon:\n",
    "    print(\"v2 not found error in dict\")\n",
    "if v3 not in lexicon:\n",
    "    print(\"v3 not found error in dict\")\n",
    "if v4 not in lexicon:\n",
    "    print(\"v4 not found error in dict\")\n",
    "\n",
    "try:\n",
    "    print('word2vec : {}'.format(similarity(vecs_wordVecs[v1] + vecs_wordVecs[v2] - vecs_wordVecs[v3], vecs_wordVecs[v4])))\n",
    "except:\n",
    "    print('error')\n",
    "\n",
    "try:\n",
    "    print('retrofitting : {}'.format(similarity(vecs_new_vec[v1] + vecs_new_vec[v2] - vecs_new_vec[v3], vecs_new_vec[v4])))\n",
    "except:\n",
    "    print('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ・「v1 + v2 - v3」と近い単語を挙げる→「v4」が結果に出るか"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 初期vecの場合，\n",
    "checkAnalogy(vecs_wordVecs, vecs_wordVecs[v1] + vecs_wordVecs[v2] - vecs_wordVecs[v3])\n",
    "print(' ')\n",
    "# newvecの場合，\n",
    "checkAnalogy(vecs_new_vec, vecs_new_vec[v1] + vecs_new_vec[v2] - vecs_new_vec[v3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
